{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse.linalg as splin\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as splg\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import ndcg_score as ndcg\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/projects/psoker/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dict_df_rating = dict()\n",
    "\n",
    "\n",
    "#1 million MovieLens \n",
    "\n",
    "df_ratings = pd.read_csv('data/ml-1m/ratings.dat', sep=\"::\", header=None)\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "df_ratings.index = list(range(len(df_ratings)))\n",
    "df_ratings.drop('timestamp', axis='columns', inplace=True)\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "dict_df_rating['ML1M'] = dict()\n",
    "dict_df_rating['ML1M']['original'] = df_ratings\n",
    "\n",
    "#Books http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "\n",
    "#df_ratings = pd.read_csv('data/Books Data/BX-Book-Ratings.csv', sep=';')\n",
    "df_ratings = pd.read_csv('data/Books Data/BX-Book-Ratings_short.csv', sep=';')\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating']\n",
    "df_ratings.index = list(range(len(df_ratings)))\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "dict_df_rating['BX'] = dict()\n",
    "dict_df_rating['BX']['original'] = df_ratings\n",
    "\n",
    "#Music  http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "#df_ratings = pd.read_csv('Digital music/ratings_Digital_Music.csv', sep=',', header=None)\n",
    "df_ratings = pd.read_csv('data/Digital music/ratings_Digital_Music_short.csv', sep=',', header=None)\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "df_ratings.index = list(range(len(df_ratings)))\n",
    "df_ratings.drop('timestamp', axis='columns', inplace=True)\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "dict_df_rating['DM'] = dict()\n",
    "dict_df_rating['DM']['original'] = df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparcity for ML1M dataset: 0.044683625622312845\n",
      "sparcity for BX dataset: 0.0027201861251949793\n",
      "sparcity for DM dataset: 0.0014640480404597422\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    all_cells = df_ratings.object_id.nunique() * df_ratings.user_id.nunique()\n",
    "    sparcity_rate = len(df_ratings) / all_cells\n",
    "    print(f'sparcity for {ds} dataset: {sparcity_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print all possible ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M [5 3 4 2 1]\n",
      "BX [10  9  5  8  6  2  7  3  4  1]\n",
      "DM [5. 3. 4. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    print(ds, df_ratings.rating.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, user_col, item_col='object_id', test_size=0.5):\n",
    "    random.seed(123)\n",
    "    test_indices = []\n",
    "    for user in df[user_col].unique():\n",
    "        df1 = df[df[user_col] == user]\n",
    "        test_ind = random.sample(df[item_col].index.tolist(), k=int(len(df1)*test_size))\n",
    "        test_indices.extend(test_ind)\n",
    "    print(len(set(test_indices)), len(test_indices))\n",
    "    test_data = df.iloc[test_indices]\n",
    "    train_data = df.drop(test_indices, axis=0)\n",
    "    return train_data, test_data\n",
    "\n",
    "def create_sparse(df, user_col, item_col, rating_col):\n",
    "    print(df[rating_col].shape, df[user_col].nunique(), df_ratings[item_col].nunique())\n",
    "    data_sparse = sparse.csr_matrix(\n",
    "        (df[rating_col].values, \n",
    "        (df[user_col].values, df[item_col].values)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return data_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257082 297398\n",
      "19529 22223\n",
      "13618 15466\n"
     ]
    }
   ],
   "source": [
    "#forming train test splitting\n",
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original'].copy()\n",
    "    \n",
    "    train_data, test_data = train_test_split(df_ratings, 'user_id', item_col='object_id', test_size=0.3)\n",
    "    \n",
    "    inner_data = set(train_data.object_id.unique()) & set(test_data.object_id.unique())\n",
    "    train_data = train_data.query(\"object_id in @inner_data\")\n",
    "    test_data = test_data.query(\"object_id in @inner_data\")\n",
    "    \n",
    "    dict_df_rating[ds]['train_original'] = train_data\n",
    "    dict_df_rating[ds]['test_original'] = test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M\n",
      "(742646,) 6040 8367\n",
      "(297346,) 6040 8367\n",
      "BX\n",
      "(61523,) 6014 8367\n",
      "(22212,) 4884 8367\n",
      "DM\n",
      "(37603,) 4316 8367\n",
      "(14855,) 3514 8367\n"
     ]
    }
   ],
   "source": [
    "#forming sparse matrixes train test\n",
    "for ds in dict_df_rating:\n",
    "    print(ds)\n",
    "    train_data = dict_df_rating[ds]['train_original'] \n",
    "    test_data = dict_df_rating[ds]['test_original']\n",
    "    \n",
    "    train_sparse = create_sparse(train_data, 'user_id', 'object_id', 'rating')\n",
    "    test_sparse = create_sparse(test_data, 'user_id', 'object_id', 'rating')\n",
    "    \n",
    "    dict_df_rating[ds]['train_sparse'] = train_sparse\n",
    "    dict_df_rating[ds]['test_sparse'] = test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M\n",
      "BX\n",
      "DM\n"
     ]
    }
   ],
   "source": [
    "#forming sparse matrixes\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    print(ds)\n",
    "    df_ratings = dict_df_rating[ds]['original'].copy()\n",
    "    \n",
    "    rows = df_ratings['user_id'].astype(\"int\")\n",
    "    cols = df_ratings['object_id'].astype(\"int\")\n",
    "\n",
    "    ratings = df_ratings.rating.astype(\"int\")\n",
    "    \n",
    "    data_sparse = sparse.csr_matrix((ratings, (rows, cols)), shape=(df_ratings.user_id.nunique(), \n",
    "                                                                df_ratings.object_id.nunique()), dtype='int32')\n",
    "    \n",
    "    dict_df_rating[ds]['sparse'] = data_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3082</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4828</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2870</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2194</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59259</th>\n",
       "      <td>3042</td>\n",
       "      <td>8364</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59260</th>\n",
       "      <td>3042</td>\n",
       "      <td>8365</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59261</th>\n",
       "      <td>3290</td>\n",
       "      <td>8366</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59262</th>\n",
       "      <td>1574</td>\n",
       "      <td>8366</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59263</th>\n",
       "      <td>3298</td>\n",
       "      <td>8366</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59264 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  object_id  rating\n",
       "0         3082          0     5.0\n",
       "1         4828          0     5.0\n",
       "2         2870          0     5.0\n",
       "3         2194          0     5.0\n",
       "4         3435          0     3.0\n",
       "...        ...        ...     ...\n",
       "59259     3042       8364     5.0\n",
       "59260     3042       8365     5.0\n",
       "59261     3290       8366     5.0\n",
       "59262     1574       8366     4.0\n",
       "59263     3298       8366     5.0\n",
       "\n",
       "[59264 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M (6040, 3706)\n",
      "BX (6195, 4958)\n",
      "DM (4838, 8367)\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    print(ds, dict_df_rating[ds]['sparse'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, data_sparse, user_vecs, item_vecs):\n",
    "    \"\"\"Recommend items for a given user given a trained model\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The id of the user we want to create recommendations for.\n",
    "        \n",
    "        data_sparse (csr_matrix): Our original training data.\n",
    "        \n",
    "        user_vecs (csr_matrix): The trained user x features vectors\n",
    "        \n",
    "        item_vecs (csr_matrix): The trained item x features vectors\n",
    "        \n",
    "        item_lookup (pandas.DataFrame): Used to map artist ids to artist names\n",
    "        \n",
    "        num_items (int): How many recommendations we want to return:\n",
    "        \n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the unknowns to 1.\n",
    "    user_interactions = user_interactions.reshape(-1) + 1 #Reshape to turn into 1D array\n",
    "    #user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "    rec_vector = (user_vecs[user_id,:] @ item_vecs.T).toarray()\n",
    "\n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1, 1))[:,0]\n",
    "    recommend_vector = user_interactions * rec_vector_scaled\n",
    "   \n",
    "    # Get all the artist indices in order of recommendations (descending) and\n",
    "    # select only the top \"num_items\" items. \n",
    "    item_idx = np.argsort(recommend_vector)[::-1]\n",
    "\n",
    "    objects = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended artist indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        objects.append(idx)\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'object_id': objects, 'score': scores})\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrix_res_dict = dict()\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    all_metrix_res = pd.DataFrame([], index = ['Recall20', 'Recall50', 'NDCG100'])\n",
    "    all_metrix_res_dict[ds] = all_metrix_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "\n",
    "\n",
    "    assert type(sparse_data) == sparse.csr_matrix, \"Matrix should be sparse in format of csr\"\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    frob = splg.norm(sparse_data, 'fro')\n",
    "    mask = sparse_data.copy()\n",
    "    mask[mask != 0] = 1\n",
    "    res_l = []\n",
    "    \n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "\n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "    \n",
    "    for iter_ in tqdm(range(iterations)):\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T @ Y\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "            u_row = sparse_data[u,:].toarray()\n",
    "            #print(((yTy + lI).shape, (u_row @ Y).T.shape))\n",
    "            X[u] = spsolve(yTy + lI, (u_row @ Y).T)\n",
    "            \n",
    "        xTx = X.T @ X\n",
    "        for i in range(item_size):\n",
    "            i_row = sparse_data[:,i].T.toarray()\n",
    "            Y[i] = spsolve(xTx + lI, (i_row @ X).T)\n",
    "            \n",
    "        res_l.append(splg.norm((X @ Y.T).multiply(mask) - sparse_data, 'fro') / frob)\n",
    "            \n",
    "        with open(f'weights/als_vectors_{iter_}_iter_{lambda_val}_lambda_{ds}_correct.pickle', 'wb') as f:\n",
    "            pickle.dump((X, Y, res_l), f)\n",
    "\n",
    "    return X, Y, res_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20750a2d01fd42408fe6d2ec5e0063c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b97126043a9463ca2f4ec58327568f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3f177842764edb90bf543f5d4d3e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5afd42eedf48908954e4475635d5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f021e6c4182d4b47b9cb6ee1d8db89a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef8d0fb869b42db9ea28291d1bfe176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ef90b20bf4210931957907a03766d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1386b6fda941411c9c4ece86c86e3328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d26bd4683374cc5bb029dd5b768f799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_res_dict = dict()\n",
    "\n",
    "for lambda_ in [0.01, 0.1, 0.3]:\n",
    "\n",
    "    for ds in dict_df_rating:\n",
    "        sparse_local = dict_df_rating[ds]['train_sparse']\n",
    "        user_vecs, item_vecs, errors = als(sparse_local, iterations=10, features=20, lambda_val=lambda_)\n",
    "        als_res_dict[ds] = (user_vecs, item_vecs, errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_ALS(train_sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "    assert type(train_sparse_data) == sparse.csr_matrix, \"Matrix should be sparse in format of csr\"\n",
    "    \n",
    "    # Calculate the foncidence for each value in our data\n",
    "    confidence = train_sparse_data * alpha_val\n",
    "\n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = train_sparse_data.shape\n",
    "\n",
    "    frob = splg.norm(train_sparse_data, 'fro')\n",
    "    \n",
    "    mask = train_sparse_data.copy()\n",
    "    mask[mask != 0] = 1\n",
    "    res_l = []\n",
    "    \n",
    "    # We create the user vectors X of size users-by-self.features, the item vectors\n",
    "    # Y of size items-by-self.features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "\n",
    "    # Precompute I and lambda * I\n",
    "    X_I = sparse.eye(user_size)\n",
    "    Y_I = sparse.eye(item_size)\n",
    "\n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "\n",
    "    for iter_ in tqdm(range(iterations)):\n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T @ Y\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "\n",
    "            # Get the user row.\n",
    "            u_row = confidence[u,:].toarray()\n",
    "            \n",
    "            # Calculate the binary preference p(u)\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "\n",
    "            # Calculate Cu and Cu - I\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            yT_CuI_y = Y.T @ CuI @ Y\n",
    "            yT_Cu_pu = Y.T @ Cu @ p_u.T\n",
    "            X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "\n",
    "        xTx = X.T @ X\n",
    "            \n",
    "        for i in range(item_size):\n",
    "            # Get the item column and transpose it.\n",
    "            i_row = confidence[:,i].T.toarray()\n",
    "\n",
    "            # Calculate the binary preference p(i)\n",
    "            p_i = i_row.copy()\n",
    "            p_i[p_i != 0] = 1.0\n",
    "\n",
    "            # Calculate Ci and Ci - I\n",
    "            CiI = sparse.diags(i_row, [0])\n",
    "            Ci = CiI + X_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            xT_CiI_x = X.T @ CiI @ X\n",
    "            xT_Ci_pi = X.T @ Ci @ p_i.T\n",
    "            Y[i] = spsolve(xTx + xT_CiI_x + lI, xT_Ci_pi)\n",
    "            \n",
    "        res_l.append(splg.norm((X @ Y.T).multiply(mask) - train_sparse_data, 'fro') / frob)\n",
    "        #print(res_l)\n",
    "        with open(f'weights/ials_vectors_{iter_}_iter_{lambda_val}_lambda_{ds}_correct.pickle', 'wb') as f:\n",
    "            pickle.dump((X, Y, res_l), f)\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe48bdbf1ea8466c9d2be5e455165c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd5728f042f4b5f8da224a1ef24147c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf740d1874f74099a87718830264d328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cf6bd1b40a40ad906c1acf403ac2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd1eb32dbeb483196cfa570e315f508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2155a4d6f9094cbe9b7cb9b220e40719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb514a5f210404688ca16b314109e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6fdb071ad04b85ac9726d740835bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d7ffa905c94f14a49e210a7f754fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ials_res_dict = dict()\n",
    "\n",
    "for lambda_ in [0.01, 0.1, 0.3]:\n",
    "    for ds in dict_df_rating:\n",
    "        sparse_local = dict_df_rating[ds]['train_sparse']\n",
    "        user_vecs, item_vecs = implicit_ALS(sparse_local, iterations=10, features=20, lambda_val=lambda_)\n",
    "        ials_res_dict[ds] = (user_vecs, item_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_als(sparse_data, iterations, lmbda, features):\n",
    "    frob = splg.norm(sparse_data, 'fro')\n",
    "    mask = sparse_data.copy()\n",
    "    mask[mask != 0] = 1\n",
    "    res_l = []\n",
    "\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features+1)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (features+1, item_size)))\n",
    "    \n",
    "    beta = np.zeros((1, user_size))\n",
    "    gamma = np.zeros((1, item_size))\n",
    "    \n",
    "    X[:, 0] = beta\n",
    "    Y[0, :] = gamma\n",
    "    \n",
    "    I = sparse.eye(features+1)\n",
    "    lI = lmbda * I\n",
    "    \n",
    "    for iter_ in tqdm(range(iterations)):\n",
    "        \n",
    "        beta = X[:,0]\n",
    "        beta = beta.reshape((1, -1))\n",
    "        X_wave = X.copy()\n",
    "        X_wave[:, 0] = np.ones((user_size, 1))\n",
    "        Y[0, :] = gamma\n",
    "        \n",
    "\n",
    "        xTx = X_wave.T @ X_wave\n",
    "\n",
    "        for i in range(item_size):\n",
    "            \n",
    "            r_i = sparse_data[:, i].T.toarray()\n",
    "            r_i_beta = r_i - beta\n",
    "            \n",
    "            Y[:,i] = spsolve(xTx + lI, (r_i_beta @ X_wave).T)\n",
    "        \n",
    "        gamma = Y[0, :]\n",
    "        Y_wave = Y.copy()\n",
    "        Y_wave[0, :] = np.ones((1, item_size))\n",
    "        X[:, 0] = beta.reshape(-1, 1)\n",
    "\n",
    "        yTy = Y_wave @ Y_wave.T\n",
    "        for u in range(user_size):\n",
    "            r_u = sparse_data[u, :].toarray()\n",
    "            r_u_gamma = r_u - gamma\n",
    "\n",
    "            X[u,:] = spsolve(Y_wave @ Y_wave.T + lI, Y_wave @ r_u_gamma.T)\n",
    "        \n",
    "        res_l.append(splg.norm((X @ Y).multiply(mask) - sparse_data, 'fro') / frob)\n",
    "        #print(res_l)\n",
    "        with open(f'weights/als_bias_vectors_{iter_}_iter_{lmbda}_lambda_{ds}_correct.pickle', 'wb') as f:\n",
    "            pickle.dump((X, Y, res_l), f)  \n",
    "                     \n",
    "    return X, Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5cf7799aab4b699307078d17f9fa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705f737a46734476ba8341e3b6b02a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4d8ea2d46b496b958a43b9cf2d6553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3147d4212914df281b473f9604b5bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514d74d76bcd490dbbec192df1e147a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c90d5de25c41d9af3a46f586fcfc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0acf71069c94b88bd6f136e5734373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4041891c0344eb9c4b2552ecf33b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd281e044c934f73827c3f1f57a48ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_bias_res_dict = dict()\n",
    "\n",
    "for lambda_ in [0.01, 0.1, 0.3]:\n",
    "    for ds in dict_df_rating:\n",
    "        sparse_local = dict_df_rating[ds]['train_sparse']\n",
    "        user_vecs, item_vecs = biased_als(sparse_local, iterations=10, features=20, lmbda=lambda_)\n",
    "        als_bias_res_dict[ds] = (user_vecs, item_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_bi(user_vecs, item_vecs, ds, method_name, threshold=0.7):\n",
    "    df_ratings = dict_df_rating[ds]['test_original']\n",
    "    all_users = df_ratings.user_id.unique()\n",
    "    user_vecs_loc, item_vecs_loc = user_vecs, item_vecs\n",
    "    sparse_local = dict_df_rating[ds]['test_sparse']\n",
    "\n",
    "    rec20_list = []\n",
    "    rec50_list = []\n",
    "    NDCG_list = []\n",
    "    multiplicator = 5 if ds != 'BX' else 10\n",
    "    #print(threshold, multiplicator, multiplicator * threshold)\n",
    "\n",
    "    for user_id in all_users:\n",
    "        recommendations = recommend(user_id, sparse_local, user_vecs_loc, item_vecs_loc)\n",
    "        dense_ratings_user = df_ratings[(df_ratings['user_id'] == user_id) & (df_ratings['rating'] > 0)]\n",
    "\n",
    "        compilation = pd.merge(dense_ratings_user, recommendations, how='inner', on = 'object_id')\n",
    "\n",
    "        if len(compilation) < 2:\n",
    "            continue\n",
    "        #dense_ratings_user.join(recommendations, on='object_id', how='inner')\n",
    "        multiplicator = [5 if ds != 'BX' else 10][0]\n",
    "        compilation['score']  = compilation.score * multiplicator\n",
    "        compilation['score_bi']  = compilation['score'].apply(lambda x: 1 if x > threshold*multiplicator else 0)\n",
    "        compilation['rating_bi'] = compilation['rating'].apply(lambda x: 1 if x > threshold*multiplicator else 0)\n",
    "        compilation['score_round'] = round(compilation.score).astype(int)\n",
    "\n",
    "        ratings = compilation.rating_bi.values\n",
    "        scores = compilation.score_bi.values\n",
    "\n",
    "        rec20 = recall(ratings, scores, k=20)\n",
    "        rec50 = recall(ratings, scores, k=50)\n",
    "        NDCG = ndcg(ratings.reshape((1, -1)), scores.reshape((1, -1)), k=100)\n",
    "\n",
    "        rec20_list.append(rec20)\n",
    "        rec50_list.append(rec50)\n",
    "        NDCG_list.append(NDCG)\n",
    "\n",
    "    metrix = []\n",
    "    for lst in [rec20_list, rec50_list, NDCG_list]:\n",
    "        metrix.append(np.mean(lst))\n",
    "\n",
    "    all_metrix_res_dict[ds][method_name] = metrix\n",
    "    \n",
    "    return metrix, compilation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, data_sparse, user_vecs, item_vecs):\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the unknowns to 1.\n",
    "    user_interactions = user_interactions.reshape(-1) #Reshape to turn into 1D array\n",
    "    #user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "    rec_vector = (user_vecs[user_id,:] @ item_vecs.T).toarray()\n",
    "\n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1, 1))[:,0]\n",
    "    recommend_vector = user_interactions * rec_vector_scaled\n",
    "   \n",
    "    # Get all the artist indices in order of recommendations (descending) and\n",
    "    # select only the top \"num_items\" items. \n",
    "    item_idx = np.argsort(recommend_vector)[::-1]\n",
    "\n",
    "    objects = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended artist indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        objects.append(idx)\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'object_id': objects, 'score': scores})\n",
    "    \n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actual, predicted, k):\n",
    "    act_set = set(actual)\n",
    "    pred_set = set(predicted[:k])\n",
    "    result = len(act_set & pred_set) / float(len(act_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_correct(user_id, data_sparse, user_vecs, item_vecs):\n",
    "  \n",
    "    recommend_vector = (user_vecs[user_id,:] @ item_vecs.T).toarray().reshape(-1)\n",
    "    print(recommend_vector)\n",
    "\n",
    "    item_idx = np.argsort(recommend_vector)[::-1]\n",
    "    print(item_idx)\n",
    "    objects = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended artist indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        objects.append(idx)\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'object_id': objects, 'score': scores})\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als_bias   ML1M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c360aed2de449fb82a22ace0ba9b7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5253e8971c28492498adf3aa19c53551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134e0bc5e9c5484383fa0315f8c26b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4025f15e885482b94543499f8b6abe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a7171ffec74bd4bd8964df28f3bf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb16e2cb98e494d80ec091c58040d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be90780291f94069adbbaf2c816491e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c66b33eef64316b33219ec9585f471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6696537bbb46ddb9f90c7b52b2efff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd276d67432343a69eac29b58f5c30fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79679c2d1aef44a396c0c93611ac1b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als_bias   BX\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c828370eccd41a0aa6f59656c814803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1846870d74484c0d8094587906974fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d05e2248df94b38a730dbc0d622b7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6632fdbbf0ea471e8378365e04b25eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fbe957a441443f801c5909e749a70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b52dbfccb845d1a43ab4d3bb492ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d940798d9e2946899699eee0f91adfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 10\n",
    "lambda_val = 0.1\n",
    "lambda_vals = [0.01, 0.1, 0.3]\n",
    "trhs = [0.4, 0.6, 0.7]\n",
    "iters = list(range(10))\n",
    "\n",
    "columns_ = ['recall20', 'recall50', 'NDCG100', 'method', 'dataset', 'lambda_val', 'iterations', 'errors', 'thresholds']\n",
    "results_models_ds_total = pd.DataFrame([], columns = columns_)\n",
    "methods = ['als_bias']\n",
    "\n",
    "for method in methods:\n",
    "    for ds in dict_df_rating:\n",
    "        print(method, ' ', ds)\n",
    "        for iter_ in tqdm(range(10)):\n",
    "            print(iter_)\n",
    "            for i in tqdm(range(len(trhs))):\n",
    "                trh = trhs[i]\n",
    "                for lambda_val in lambda_vals:\n",
    "\n",
    "                    with open(f'weights/{method}_vectors_{iter_}_iter_{lambda_val}_lambda_{ds}_correct.pickle', 'rb') as f:\n",
    "                        user_vecs, item_vecs, errors = pickle.load(f)\n",
    "                    \n",
    "                    if method == 'als_bias':\n",
    "                        item_vecs = item_vecs.T\n",
    "                        \n",
    "                    metrix, _ = get_evaluation_bi(user_vecs, item_vecs, ds, 'ALS', threshold=trh)\n",
    "                    metrix.extend([method, ds, lambda_val, iter_+1, errors[-1], trh])\n",
    "\n",
    "                    results_models_ds_total = results_models_ds_total.append(dict(zip(columns_, metrix)), ignore_index=True)\n",
    "                    \n",
    "            with open(f'weights/result_table_{method}_{ds}_{iter_}.pickle', 'wb') as f:\n",
    "                pickle.dump(results_models_ds_total, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall20</th>\n",
       "      <th>recall50</th>\n",
       "      <th>NDCG100</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>lambda_val</th>\n",
       "      <th>iterations</th>\n",
       "      <th>errors</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680944</td>\n",
       "      <td>0.725435</td>\n",
       "      <td>0.937646</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909573</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672908</td>\n",
       "      <td>0.715659</td>\n",
       "      <td>0.936668</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929702</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692295</td>\n",
       "      <td>0.735543</td>\n",
       "      <td>0.939903</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695526</td>\n",
       "      <td>0.755178</td>\n",
       "      <td>0.826419</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909573</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691798</td>\n",
       "      <td>0.748302</td>\n",
       "      <td>0.825207</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929702</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.843775</td>\n",
       "      <td>0.845757</td>\n",
       "      <td>0.923339</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902623</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.845559</td>\n",
       "      <td>0.847145</td>\n",
       "      <td>0.923458</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.856463</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.926436</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902938</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.858247</td>\n",
       "      <td>0.860230</td>\n",
       "      <td>0.925945</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902623</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.859040</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.926068</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recall20  recall50   NDCG100    method dataset  lambda_val iterations  \\\n",
       "0    0.680944  0.725435  0.937646  als_bias    ML1M        0.01          1   \n",
       "1    0.672908  0.715659  0.936668  als_bias    ML1M        0.10          1   \n",
       "2    0.692295  0.735543  0.939903  als_bias    ML1M        0.30          1   \n",
       "3    0.695526  0.755178  0.826419  als_bias    ML1M        0.01          1   \n",
       "4    0.691798  0.748302  0.825207  als_bias    ML1M        0.10          1   \n",
       "..        ...       ...       ...       ...     ...         ...        ...   \n",
       "265  0.843775  0.845757  0.923339  als_bias      DM        0.10         10   \n",
       "266  0.845559  0.847145  0.923458  als_bias      DM        0.30         10   \n",
       "267  0.856463  0.858644  0.926436  als_bias      DM        0.01         10   \n",
       "268  0.858247  0.860230  0.925945  als_bias      DM        0.10         10   \n",
       "269  0.859040  0.860825  0.926068  als_bias      DM        0.30         10   \n",
       "\n",
       "       errors  thresholds  \n",
       "0    0.909573         0.4  \n",
       "1    0.929702         0.4  \n",
       "2    0.946281         0.4  \n",
       "3    0.909573         0.6  \n",
       "4    0.929702         0.6  \n",
       "..        ...         ...  \n",
       "265  0.902623         0.6  \n",
       "266  0.902256         0.6  \n",
       "267  0.902938         0.7  \n",
       "268  0.902623         0.7  \n",
       "269  0.902256         0.7  \n",
       "\n",
       "[270 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'als_bias'\n",
    "ds = 'DM'\n",
    "iter_ = 9\n",
    "lambda_val\n",
    "\n",
    "with open(f'metrics/result_table_{method}_{ds}_{iter_}.pickle', 'rb') as f:\n",
    "    df_result = pickle.load(f)\n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall20</th>\n",
       "      <th>recall50</th>\n",
       "      <th>NDCG100</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>lambda_val</th>\n",
       "      <th>iterations</th>\n",
       "      <th>errors</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680944</td>\n",
       "      <td>0.725435</td>\n",
       "      <td>0.937646</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909573</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.679702</td>\n",
       "      <td>0.720961</td>\n",
       "      <td>0.938061</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.681690</td>\n",
       "      <td>0.723198</td>\n",
       "      <td>0.938137</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.817690</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.683347</td>\n",
       "      <td>0.727589</td>\n",
       "      <td>0.938276</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814144</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.729992</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.812840</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.685336</td>\n",
       "      <td>0.731234</td>\n",
       "      <td>0.938544</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.812304</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.731732</td>\n",
       "      <td>0.938560</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.812070</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.687241</td>\n",
       "      <td>0.732229</td>\n",
       "      <td>0.938539</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.811971</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.687490</td>\n",
       "      <td>0.732974</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>0.811940</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.687158</td>\n",
       "      <td>0.731897</td>\n",
       "      <td>0.938555</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>ML1M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.932890</td>\n",
       "      <td>0.933306</td>\n",
       "      <td>0.981176</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.935524</td>\n",
       "      <td>0.935940</td>\n",
       "      <td>0.981454</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.942363</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.936911</td>\n",
       "      <td>0.937327</td>\n",
       "      <td>0.981548</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934963</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.937327</td>\n",
       "      <td>0.937465</td>\n",
       "      <td>0.981650</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.933246</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.937604</td>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.981695</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.932730</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.938297</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.932516</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.938020</td>\n",
       "      <td>0.938297</td>\n",
       "      <td>0.981815</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.932396</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.937465</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.981813</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.932317</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.937465</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.981816</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>0.932262</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.981811</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>BX</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.932225</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.912173</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974542</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.915147</td>\n",
       "      <td>0.915940</td>\n",
       "      <td>0.969367</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.919107</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.916534</td>\n",
       "      <td>0.917922</td>\n",
       "      <td>0.969562</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909172</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.919707</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.969968</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.906246</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.921491</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.970240</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.904996</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.922284</td>\n",
       "      <td>0.923473</td>\n",
       "      <td>0.970511</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.904305</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.923275</td>\n",
       "      <td>0.924861</td>\n",
       "      <td>0.970759</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.903832</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.923870</td>\n",
       "      <td>0.925456</td>\n",
       "      <td>0.970896</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.903470</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.922879</td>\n",
       "      <td>0.924663</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>0.903178</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.924663</td>\n",
       "      <td>0.970659</td>\n",
       "      <td>als_bias</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902938</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     recall20  recall50   NDCG100    method dataset  lambda_val iterations  \\\n",
       "0    0.680944  0.725435  0.937646  als_bias    ML1M        0.01          1   \n",
       "9    0.679702  0.720961  0.938061  als_bias    ML1M        0.01          2   \n",
       "18   0.681690  0.723198  0.938137  als_bias    ML1M        0.01          3   \n",
       "27   0.683347  0.727589  0.938276  als_bias    ML1M        0.01          4   \n",
       "36   0.684341  0.729992  0.938469  als_bias    ML1M        0.01          5   \n",
       "45   0.685336  0.731234  0.938544  als_bias    ML1M        0.01          6   \n",
       "54   0.686827  0.731732  0.938560  als_bias    ML1M        0.01          7   \n",
       "63   0.687241  0.732229  0.938539  als_bias    ML1M        0.01          8   \n",
       "72   0.687490  0.732974  0.938579  als_bias    ML1M        0.01          9   \n",
       "81   0.687158  0.731897  0.938555  als_bias    ML1M        0.01         10   \n",
       "90   0.932890  0.933306  0.981176  als_bias      BX        0.01          1   \n",
       "99   0.935524  0.935940  0.981454  als_bias      BX        0.01          2   \n",
       "108  0.936911  0.937327  0.981548  als_bias      BX        0.01          3   \n",
       "117  0.937327  0.937465  0.981650  als_bias      BX        0.01          4   \n",
       "126  0.937604  0.937881  0.981695  als_bias      BX        0.01          5   \n",
       "135  0.937881  0.938297  0.981753  als_bias      BX        0.01          6   \n",
       "144  0.938020  0.938297  0.981815  als_bias      BX        0.01          7   \n",
       "153  0.937465  0.937743  0.981813  als_bias      BX        0.01          8   \n",
       "162  0.937465  0.937743  0.981816  als_bias      BX        0.01          9   \n",
       "171  0.937743  0.937881  0.981811  als_bias      BX        0.01         10   \n",
       "180  0.912173  0.912768  0.968987  als_bias      DM        0.01          1   \n",
       "189  0.915147  0.915940  0.969367  als_bias      DM        0.01          2   \n",
       "198  0.916534  0.917922  0.969562  als_bias      DM        0.01          3   \n",
       "207  0.919707  0.920896  0.969968  als_bias      DM        0.01          4   \n",
       "216  0.921491  0.922680  0.970240  als_bias      DM        0.01          5   \n",
       "225  0.922284  0.923473  0.970511  als_bias      DM        0.01          6   \n",
       "234  0.923275  0.924861  0.970759  als_bias      DM        0.01          7   \n",
       "243  0.923870  0.925456  0.970896  als_bias      DM        0.01          8   \n",
       "252  0.922879  0.924663  0.970634  als_bias      DM        0.01          9   \n",
       "261  0.923077  0.924663  0.970659  als_bias      DM        0.01         10   \n",
       "\n",
       "       errors  thresholds  \n",
       "0    0.909573         0.4  \n",
       "9    0.829673         0.4  \n",
       "18   0.817690         0.4  \n",
       "27   0.814144         0.4  \n",
       "36   0.812840         0.4  \n",
       "45   0.812304         0.4  \n",
       "54   0.812070         0.4  \n",
       "63   0.811971         0.4  \n",
       "72   0.811940         0.4  \n",
       "81   0.811947         0.4  \n",
       "90   0.977760         0.4  \n",
       "99   0.942363         0.4  \n",
       "108  0.934963         0.4  \n",
       "117  0.933246         0.4  \n",
       "126  0.932730         0.4  \n",
       "135  0.932516         0.4  \n",
       "144  0.932396         0.4  \n",
       "153  0.932317         0.4  \n",
       "162  0.932262         0.4  \n",
       "171  0.932225         0.4  \n",
       "180  0.974542         0.4  \n",
       "189  0.919107         0.4  \n",
       "198  0.909172         0.4  \n",
       "207  0.906246         0.4  \n",
       "216  0.904996         0.4  \n",
       "225  0.904305         0.4  \n",
       "234  0.903832         0.4  \n",
       "243  0.903470         0.4  \n",
       "252  0.903178         0.4  \n",
       "261  0.902938         0.4  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambda_val = 0.01\n",
    "thresholds = 0.4\n",
    "ds = 'DM'\n",
    "\n",
    "df_loc = df_result[(df_result.lambda_val == lambda_val) & \\\n",
    "                   (df_result.thresholds == thresholds) & \\\n",
    "                   (df_result.dataset == ds)\n",
    "                  ]\n",
    "plt.plot(df_loc.iterations, df_loc.recall20, label = 'recall20')\n",
    "plt.plot(df_loc.iterations, df_loc.recall50, label = 'recall50')\n",
    "plt.plot(df_loc.iterations, df_loc.NDCG100, label = 'NDCG100')\n",
    "plt.legend()\n",
    "plt.title(f'Dataset {method}, method {ds}, lambda {lambda_val}')\n",
    "plt.xlabel('iterations')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('metrics/df_final_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
